#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{graphicx}
\pagestyle{empty}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family sfdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 10
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 1.5cm
\rightmargin 2cm
\bottommargin 1.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Part*
Screenful gesture library API
\end_layout

\begin_layout Paragraph*
August 6th, 2014
\end_layout

\begin_layout Section*
Overview
\end_layout

\begin_layout Standard
Screenful gesture library utilizes OpenNI 2.2 and NiTE 2.2 middleware to send
 user interface commands to a browser running the Screenful dashboard software.
 This allows users to interact with the screen without external input devices.
 The gestures are detected by server software running on a computer with
 a depth sensor connected.
\end_layout

\begin_layout Standard
A browser can initiate a WebSocket connection to the gesture server, handle
 the available events as they are received from the server and carry out
 the UI commands in Javascript.
 The server uses Java-WebSocket (
\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

http://java-websocket.org/
\end_layout

\end_inset

) and operates stand-alone.
\end_layout

\begin_layout Standard
The gesture server has been developed for Asus Xtion Pro.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The NiTE hand tracker did not seem to work with the Kinect.
\end_layout

\end_inset

 The server is run via Java Service Wrapper, which takes care of restarts
 on crashes, logging and integration into system services.
 Configuration of parameters and library paths is done via 
\family typewriter
server.conf
\family default
 and 
\family typewriter
libpaths.conf
\family default
.
\end_layout

\begin_layout Standard
Since the server operates over a WebSocket, it can control multiple browsers
 running anywhere on the network.
 There is also no practical limitation on the number of hands tracked simultaneo
usly as long as they fit in the field of view of the sensor.
\end_layout

\begin_layout Standard
The messages sent over the WebSocket are simple strings, like 
\begin_inset Quotes eld
\end_inset

left
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

right
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

out
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

user-exit
\begin_inset Quotes erd
\end_inset

.
 The server program is accompanied with a configuration file that allows
 setting which directional gestures are recognized and sent and which are
 used to stop interaction.
 The server also sends events when hand tracking starts and stops.
 These messages should be handled by the Javascript in the browser.
\end_layout

\begin_layout Section*
Gesture recognition
\end_layout

\begin_layout Standard
Gesture recognition is implemented in a simple way by tracking movement
 between frames - not depth frames but hand and user tracker frames from
 NiTE.
 A NiTE hand tracker frame is a data container of all currently detected
 hands (and other information) that the library has recognized from the
 depth data.
 Likewise user tracker frames contain all currently tracked users and their
 skeleton joint positions.
\end_layout

\begin_layout Standard
The hand tracker is used to supply coordinates of tracked hands - the user
 should wave or push with their palm at the sensor to start tracking - and
 these coordinates are inspected between two consecutive frames.
 The Gesture class implements keeping track of how many frames a motion
 has been performed for and it uses a class implementing the Detector interface
 to determine if the movement was appropriate.
\end_layout

\begin_layout Standard
In the simple case of directional gestures, a DirectionDetector compares
 the motion vector between the hand points of current and the previous hand
 tracker frame, and determines whether a hand was moving mainly in some
 of the cardinal directions (left / right / up / down / in / out).
 When the DirectionDetector has returned 
\begin_inset Quotes eld
\end_inset

true
\begin_inset Quotes erd
\end_inset

 enough times when a Gesture uses it, the Gesture triggers and notifies
 its listeners that a directional gesture has been recognized.
\end_layout

\begin_layout Standard
In practice this means that for each frame the DirectionDetector tells if
 the movement was big enough and which direction it was, and when this has
 happened enough times in a row, the hand has moved towards the direction.
 The parameters that can be adjusted is initial delay after hand tracking
 starts and gestures are sent (in milliseconds, to avoid accidental gestures
 after waving), the minimum distance that a hand needs to move per frame
 (in millimeters) to be considered moving, and the amount of frames the
 movement needs to continue to the same general direction.
\end_layout

\begin_layout Standard
The intermediate tracking object, NiTETracker keeps track of both hand and
 user trackers and can be queried for any tracking information.
 It also handles USB disconnects and waits for the sensor to be plugged
 back in again.
 The skeleton joints could be used with the gesture detection similarly
 to hand coordinates, but as of now it is unimplemented due to the hand
 tracker being more suitable for this application.
\end_layout

\begin_layout Standard
After creating a NiTETracker object, you can add a HandsListener, BonesListener
 or TrackingListener to it to receive hand tracker frames, user tracker
 frames or notifications of start/stop of hand tracking, respectively.
 To look for directional gestures from the hand tracker, one would create
 a Gesture, giving it a DirectionDetector in the constructor along with
 the parameters, then attach the Gesture to NiTETracker's hand listeners.
 Then a class implementing GestureListener can be added to the gesture's
 listeners and receive direction events as they're recognized.
\end_layout

\begin_layout Section*
Public class members:
\end_layout

\begin_layout Standard

\shape italic
For readability, classes and methods that contribute to the library generally
 use 
\begin_inset Quotes eld
\end_inset

Hands
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

Bones
\begin_inset Quotes erd
\end_inset

 in their names when referring to 
\begin_inset Quotes eld
\end_inset

hand tracking
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

skeletal tracking
\begin_inset Quotes erd
\end_inset

 functionality to distinguish them from 
\begin_inset Quotes eld
\end_inset

Hand
\begin_inset Quotes erd
\end_inset

/
\begin_inset Quotes erd
\end_inset

User
\begin_inset Quotes erd
\end_inset

/
\begin_inset Quotes erd
\end_inset

Skeleton
\begin_inset Quotes erd
\end_inset

 used in NiTE naming scheme.
 Accessors will work as expected, ie.
 NiTETracker.getUserTracker() will return a NiTE UserTracker.
\end_layout

\begin_layout Subsection*
screenful.server - main server program
\end_layout

\begin_layout Itemize

\series bold
GestureServer
\series default
: The main application for browser communication.
 Implements a WebSocket server for a browser to connect to and passes detected
 gestures to the UI.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
main(String[] args)
\end_layout

\begin_deeper
\begin_layout Itemize
Initializes NiTETracker and gesture detection and starts listening for web
 socket connections.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
onClose(WebSocket conn, int code, String reason, boolean remote)
\end_layout

\begin_deeper
\begin_layout Itemize
Actions to be done when a socket closes
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
onError(WebSocket conn, Exception ex)
\end_layout

\begin_deeper
\begin_layout Itemize
Actions to be done when an error occurs with the WebSocket
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
onMessage(WebSocket conn, String message)
\end_layout

\begin_deeper
\begin_layout Itemize
Actions to be done when a message is received
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
onOpen(WebSocket conn, ClientHandShake handshake)
\end_layout

\begin_deeper
\begin_layout Itemize
Actions to be done when a connection is opened
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
GestureServer.Messenger
\series default
: Inner class of GestureServer sends the command to the browser via WebSockets.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
onGesture(Displacement gesture)
\end_layout

\begin_deeper
\begin_layout Itemize
When a detected gesture notifies the Messenger, it checks whether the gesture
 is assigned to exiting interaction or providing input and either stops
 hand tracking or sends the appropriate messages over WebSockets.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
Settings
\series default
: A settings object for the GestureServer.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
Settings()
\end_layout

\begin_deeper
\begin_layout Itemize
Create default settings
\end_layout

\begin_layout Itemize
Default filename 
\begin_inset Quotes eld
\end_inset

default.conf
\begin_inset Quotes erd
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Settings(String filename)
\end_layout

\begin_deeper
\begin_layout Itemize
Load settings from a configuration file
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
save()
\end_layout

\begin_deeper
\begin_layout Itemize
Saves the current settings
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection*
screenful.basic - reading NiTE data
\end_layout

\begin_layout Itemize

\series bold
BonesListener (Interface)
\series default
: Any class that wants skeleton data should implement this interface and
 add itself to NiTETracker's bones listeners.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
onNewBonesFrame(UserTrackerFrameRef frame)
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HandsListener (Interface)
\series default
: Any class that wants hand data should implement this interface and add
 itself to NiTETracker's hands listeners.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
onNewHandFrame(HandTrackerFrameRef frame)
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
TrackingListener (Interface)
\series default
: Listener interface to receive hand tracking start/stop events.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
onHandTrackingStarted()
\end_layout

\begin_deeper
\begin_layout Itemize
Called when hand tracking starts.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
onHandTrackingStopped()
\end_layout

\begin_deeper
\begin_layout Itemize
Called when hand tracking stops (there are no more tracked hands).
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
\color black
NiTETracker
\series default
\color inherit
: Tracker for NUI features (implements HandListener and SkeletonListener
 from the NiTE library).
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
NiTETracker(boolean enableHands, boolean enableBones)
\end_layout

\begin_deeper
\begin_layout Itemize
Constructor, true will enable hand and/or user tracker and false will disable
 them.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
addBonesListener(BonesListener listener) / removeBonesListener(BonesListener
 listener)
\end_layout

\begin_deeper
\begin_layout Itemize
Add/remove a listener for user tracking
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
addHandsListener(HandsListener listener) / removeHandsListener(HandsListener
 listener)
\end_layout

\begin_deeper
\begin_layout Itemize
Add/remove a listener for hand tracking
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
addTrackingListener(TrackingListener listener) / removeTrackingListener(Tracking
Listener listener)
\end_layout

\begin_deeper
\begin_layout Itemize
Add/remove a listener for hand tracker start/stop events.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
removeAllListeners()
\end_layout

\begin_deeper
\begin_layout Itemize
Clears all listener lists.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
forgetHand(short id)
\end_layout

\begin_deeper
\begin_layout Itemize
Stop tracking a specific tracked hand ID
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
forgetHands()
\end_layout

\begin_deeper
\begin_layout Itemize
Stop tracking all tracked hands
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getBones()
\end_layout

\begin_deeper
\begin_layout Itemize
Return currently detected skeletons
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getBufferedImage(): BufferedImage
\end_layout

\begin_deeper
\begin_layout Itemize
Return the buffered depth image
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getHandFrame(): HandTrackerFrameRef
\end_layout

\begin_deeper
\begin_layout Itemize
Return current hand tracker frame
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getHandTracker(): HandTracker
\end_layout

\begin_deeper
\begin_layout Itemize
Return the hand tracker
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\color black
getHands(): List<HandData>
\end_layout

\begin_deeper
\begin_layout Itemize
Get hand tracking data
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getTrackedHands(): List<HandData>
\end_layout

\begin_deeper
\begin_layout Itemize
Get a list of hands that are being tracked (a hand ID can be present but
 not tracked)
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getUserFrame(): UserTrackerFrameRef
\end_layout

\begin_deeper
\begin_layout Itemize
Return current user tracker frame
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getUserTracker(): UserTracker
\end_layout

\begin_deeper
\begin_layout Itemize
Return the user tracker
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\color black
getBones(): List<UserData>
\end_layout

\begin_deeper
\begin_layout Itemize
Get skeleton data
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
onDeviceConnected(DeviceInfo di)
\end_layout

\begin_deeper
\begin_layout Itemize
Handles OpenNI's device state changes
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
onDeviceDisconnected(DeviceInfo di)
\end_layout

\begin_deeper
\begin_layout Itemize
Handles OpenNI's device state changes
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
onNewFrame(HandTracker ht)
\end_layout

\begin_deeper
\begin_layout Itemize
Handles hand tracker frames
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
onNewFrame(UserTracker ut)
\end_layout

\begin_deeper
\begin_layout Itemize
Handles user tracker frames
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection*
screenful.detectors - movement detection in frames
\end_layout

\begin_layout Itemize

\series bold
ConsecutiveFrames
\series default
:
\series bold
 
\series default
A container object for passing two consecutive hand and user tracker frames.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
ConsecutiveFrames(HandTrackerFrameRef handsFrame, HandTrackerFrameRef previousHa
ndsFrame, UserTrackerFrameRef bonesFrame, UserTrackerFrameRef previousBonesFrame
)
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Detector
\series default
:
\series bold
 
\series default
Interface for detectors, ie.
 an object that determines whether the movement of something during two
 consecutive (hand and/or skeleton) frames was appropriate (true / false).
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
detected(ConsecutiveFrames frames): boolean
\end_layout

\begin_layout Itemize

\series bold
getData(): GestureData
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
DirectionDetector
\series default
:
\series bold
 
\series default
Detects hand point movement direction by calculating the displacement vector
 of each hand point (could also use skeletons) between two consecutive frames.
 When any tracked hand performs a big enough movement (sensitivity set in
 millimeters), the detected(..) method returns true.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
getSensitivity(): int
\end_layout

\begin_layout Itemize

\series bold
setSensitivity(int sensitivity)
\end_layout

\begin_layout Itemize

\series bold
DirectionDetector(int sensitivity)
\end_layout

\begin_deeper
\begin_layout Itemize
constructor
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
detected(ConsecutiveFrames frames): boolean
\end_layout

\begin_layout Itemize

\series bold
getData(): GestureData 
\end_layout

\end_deeper
\begin_layout Subsection*
screenful.gestures - gesture detection based on movement
\end_layout

\begin_layout Itemize

\series bold
Gesture
\series default
: Gesture implements a generic gesture that notifies its listeners when
 a gesture has been detected for long enough.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
Gesture(Detector detector, int framecount, int cooldown)
\end_layout

\begin_deeper
\begin_layout Itemize
Create a new gesture using a specified Detector.
 Framecount is the amount of consecutive frames where the detector's condition
 should be true for the gesture to be recognized.
 Cooldown is in milliseconds and defines a period of inaction after a gesture
 has been successfully detected.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
addListener(GestureListener listener)
\end_layout

\begin_deeper
\begin_layout Itemize
Add a listener for the gesture
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
onNewBonesFrame(UserTrackerFrameRef frame)
\end_layout

\begin_deeper
\begin_layout Itemize
Handle user tracker frames
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
onNewHandsFrame(HandTrackerFrameRef frame)
\end_layout

\begin_deeper
\begin_layout Itemize
Handle hand tracker frames
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
GestureListener
\series default
: A class that wants notifications when a gesture is detected should implement
 GestureListener and add itself to the gesture's listeners.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
onGesture(GestureData gesture)
\end_layout

\begin_deeper
\begin_layout Itemize
Override to implement behavior
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
JointMetrics
\series default
: Static methods for getting skeleton measurements etc.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
jointToJointDistance(UserData user, JointType from, JointType to): double
\end_layout

\begin_deeper
\begin_layout Itemize
Returns euclidian distance in space between two skeletal joints, eg.
 JointType.RIGHT_HAND, JointType.NECK etc.
 in millimeters
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
Poses
\series default
: Methods to detect skeletal poses based on joint positions, eg.
 
\begin_inset Quotes eld
\end_inset

hands above neck
\begin_inset Quotes erd
\end_inset

 etc.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
dorkyClick(UserData user): boolean
\end_layout

\begin_deeper
\begin_layout Itemize
Returns true if hands are above the neck and distance between the hands
 was less than 150 mm.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
handsAboveNeck(UserData user): boolean
\end_layout

\begin_deeper
\begin_layout Itemize
Returns true if a user's both hands are above the neck.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
Utilities
\series default
: Some general utility methods
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
convertPoint(Point3D nitepoint): javafx.Geometry.Point3D
\end_layout

\begin_deeper
\begin_layout Itemize
Convert a NiTE Point3D into javafx Point3D and round the coordinates to
 integers
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
determineCardinalDirection(javafx.geometry.Point3D vector, int minSensitivity):
 CardinalDirection
\end_layout

\begin_deeper
\begin_layout Itemize
Return a cardinal direction that most closely matches the vector
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
displacementVector(Point3D from, Point3D to): javafx.geometry.Point3D
\end_layout

\begin_deeper
\begin_layout Itemize
Calculate displacement vector between two points
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
distance3d(Point3D from, Point3D to): double
\end_layout

\begin_deeper
\begin_layout Itemize
Return distance between two 3D points
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection*
screenful.gestures.detectors
\end_layout

\begin_layout Itemize

\series bold
ConsecutiveFrames
\series default
: A container for passing two consecutive hand and user tracker frames.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
ConsecutiveFrames(HandTrackerFrameRef handsFrame, HandTrackerFrameRef previousHa
ndsFrame, UserTrackerFrameRef bonesFrame, UserTrackerFrameRef previousBonesFrame
)
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Detector
\series default
: An interface for defining frame-to-frame detection logic.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
detected(ConsecutiveFrames frames): boolean
\end_layout

\begin_deeper
\begin_layout Itemize
Override.
 Should return true when the difference between frames is appropriate.
 A Gesture will use this boolean value to determine if a frame contributed
 to the gesture.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getData(): Displacement
\end_layout

\begin_deeper
\begin_layout Itemize
Return last direction data.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
DirectionDetector
\series default
: Detect movement in the cardinal directions.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
detected(ConsecutiveFrames frames): boolean
\end_layout

\begin_deeper
\begin_layout Itemize
Returns true when big enough movement is detected towards some direction.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getData(): Displacement
\end_layout

\begin_deeper
\begin_layout Itemize
Return last direction data.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getSensitivity(): int
\end_layout

\begin_deeper
\begin_layout Itemize
Return the chosen sensitivity.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
setSensitivity(int sensitivity)
\end_layout

\begin_deeper
\begin_layout Itemize
Set the sensitivity in millimeters.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
Displacement
\series default
: Extra data related to a detected gesture.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
Displacement(CardinalDirection direction)
\end_layout

\begin_layout Itemize

\series bold
Displacement(Point3D directionVector, CardinalDirection direction)
\end_layout

\begin_layout Itemize

\series bold
Displacement(Point3D directionVector, CardinalDirection direction, short
 id)
\end_layout

\begin_deeper
\begin_layout Itemize
Constructors
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getDirection(): CardinalDirection
\end_layout

\begin_deeper
\begin_layout Itemize
Return cardinal direction of displacement (left/right/up/down/in/out)
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getDirectionVector(): Point3D
\end_layout

\begin_deeper
\begin_layout Itemize
Return 3D vector of displacement 
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
getId(): short
\end_layout

\begin_deeper
\begin_layout Itemize
Get the ID
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
setDirection(CardinalDirection dir)
\end_layout

\begin_deeper
\begin_layout Itemize
Set the direction
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
setDirectionVector(Point3D directionVector)
\end_layout

\begin_deeper
\begin_layout Itemize
Set the vector
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection*
screenful.gui - GUI windows
\end_layout

\begin_layout Itemize

\series bold
GenericWindow
\series default
: Generic frame for displaying graphics
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
run()
\end_layout

\end_deeper
\begin_layout Subsection*
screenful.gui.rendering - graphics renderers for GUI windows
\end_layout

\begin_layout Itemize

\series bold
HandsRenderer
\series default
: Draw tracked hands (red rectangles when tracking) on top of depth image.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
onNewHandsFrame(HandTrackerFrameRef frame)
\end_layout

\begin_layout Itemize

\series bold
paint(Graphics g)
\end_layout

\begin_deeper
\begin_layout Itemize
Draw depth image and tracked hands.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
BonesRenderer
\series default
: Draw stick characters from skeleton data on top of depth image.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
onNewBonesFrame(UserTrackerFrameRef frame)
\end_layout

\begin_layout Itemize

\series bold
paint(Graphics g)
\end_layout

\begin_deeper
\begin_layout Itemize
Draw depth image and skeletons.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
DirectionRenderer
\series default
: Draw some feedback to directional gestures.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
onGesture(GestureData gesture)
\end_layout

\begin_layout Itemize

\series bold
paint(Graphics g)
\end_layout

\begin_deeper
\begin_layout Itemize
Draw text to indicate directions.
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection*
screenful.gui.visualization - containers for GUI windows
\end_layout

\begin_layout Itemize

\series bold
Visualization (Interface)
\series default
: Interface for classes that provide some sort of graphical presentation
 of the sensor data.
 A visualization will take a NiTETracker in its constructor to start listening
 to events.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
show()
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
DirectionVisualization
\series default
: Directional gesture visualization window
\end_layout

\begin_layout Itemize

\series bold
HandsVisualization
\series default
: Hand tracker visualization window
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
show()
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
BonesVisualization
\series default
: Skeleton tracker visualization window
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
show()
\end_layout

\end_deeper
\begin_layout Subsection*
screenful.testapps - applications for testing
\end_layout

\begin_layout Itemize

\series bold
BonesAndHandsViewer
\series default
: Views both input methods (skeleton / hand) simultaneously.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
main(String[] args)
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HandsDirectionViewer
\series default
: Show general direction of tracked hand movement.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
main(String[] args)
\end_layout

\end_deeper
\end_body
\end_document
